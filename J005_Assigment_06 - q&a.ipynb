{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":799923,"sourceType":"datasetVersion","datasetId":374}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport transformers\nimport json\nimport warnings\nfrom datasets import Dataset\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-31T03:26:09.741406Z","iopub.execute_input":"2024-08-31T03:26:09.742158Z","iopub.status.idle":"2024-08-31T03:26:14.844732Z","shell.execute_reply.started":"2024-08-31T03:26:09.742119Z","shell.execute_reply":"2024-08-31T03:26:14.843778Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/stanford-question-answering-dataset/train-v1.1.json') as train_file:\n    train_data = json.load(train_file)\n\nwith open('/kaggle/input/stanford-question-answering-dataset/dev-v1.1.json') as dev_file:\n    dev_data = json.load(dev_file)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T03:26:14.846504Z","iopub.execute_input":"2024-08-31T03:26:14.846987Z","iopub.status.idle":"2024-08-31T03:26:16.186911Z","shell.execute_reply.started":"2024-08-31T03:26:14.846950Z","shell.execute_reply":"2024-08-31T03:26:16.186078Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def prepare_dataset(data):\n    contexts = []\n    questions = []\n    answers = []\n\n    for article in data['data']:\n        for paragraph in article['paragraphs']:\n            context = paragraph['context']\n            for qa in paragraph['qas']:\n                question = qa['question']\n                answer = qa['answers'][0]  # Take the first answer\n                answer['text'] = answer['text']\n                answer['answer_start'] = answer['answer_start']\n\n                contexts.append(context)\n                questions.append(question)\n                answers.append(answer)\n    \n    return Dataset.from_dict({'context': contexts, 'question': questions, 'answers': answers})","metadata":{"execution":{"iopub.status.busy":"2024-08-31T03:26:16.188061Z","iopub.execute_input":"2024-08-31T03:26:16.188384Z","iopub.status.idle":"2024-08-31T03:26:16.195413Z","shell.execute_reply.started":"2024-08-31T03:26:16.188350Z","shell.execute_reply":"2024-08-31T03:26:16.194523Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_dataset = prepare_dataset(train_data)\ndev_dataset = prepare_dataset(dev_data)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T03:26:16.198013Z","iopub.execute_input":"2024-08-31T03:26:16.198385Z","iopub.status.idle":"2024-08-31T03:26:17.209581Z","shell.execute_reply.started":"2024-08-31T03:26:16.198343Z","shell.execute_reply":"2024-08-31T03:26:17.208719Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_name='distilbert-base-uncased'\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T03:26:17.210798Z","iopub.execute_input":"2024-08-31T03:26:17.211377Z","iopub.status.idle":"2024-08-31T03:26:20.587222Z","shell.execute_reply.started":"2024-08-31T03:26:17.211329Z","shell.execute_reply":"2024-08-31T03:26:20.586463Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb20fdc84af84c8b9497eccb2b6821b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d62a980ee4ec43debc3a0d467d383c99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e458143489443638a689e56125c6af1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c0e184149fd4564a5305c21a864a3ae"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    questions = [q.strip() for q in examples['question']]\n    inputs = tokenizer(\n        questions,\n        examples['context'],\n        max_length=384,\n        truncation=True,\n        padding=\"max_length\",\n        return_offsets_mapping=True,  # Now supported by the fast tokenizer\n        return_tensors=\"pt\"\n    )\n    \n    start_positions = []\n    end_positions = []\n    \n    for i, answer in enumerate(examples['answers']):\n        start_positions.append(answer['answer_start'])\n        end_positions.append(answer['answer_start'] + len(answer['text']))\n    \n    inputs.update({\n        \"start_positions\": start_positions,\n        \"end_positions\": end_positions,\n    })\n    \n    return inputs","metadata":{"execution":{"iopub.status.busy":"2024-08-31T03:26:20.588323Z","iopub.execute_input":"2024-08-31T03:26:20.588641Z","iopub.status.idle":"2024-08-31T03:26:20.595553Z","shell.execute_reply.started":"2024-08-31T03:26:20.588606Z","shell.execute_reply":"2024-08-31T03:26:20.594623Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\ntokenized_dev_dataset = dev_dataset.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T03:26:20.596808Z","iopub.execute_input":"2024-08-31T03:26:20.597412Z","iopub.status.idle":"2024-08-31T03:31:10.655590Z","shell.execute_reply.started":"2024-08-31T03:26:20.597368Z","shell.execute_reply":"2024-08-31T03:31:10.654638Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/87599 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de1d3657bac54bff8da21b91d8a1a645"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10570 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2319c478a7d463c9e5f2601ba9b07a5"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T03:31:10.656693Z","iopub.execute_input":"2024-08-31T03:31:10.657035Z","iopub.status.idle":"2024-08-31T03:31:39.334137Z","shell.execute_reply.started":"2024-08-31T03:31:10.657000Z","shell.execute_reply":"2024-08-31T03:31:39.333210Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01fc311a91c94e8a8c2cac443318194d"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=2,\n    weight_decay=0.01,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_dev_dataset\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-31T03:31:39.335368Z","iopub.execute_input":"2024-08-31T03:31:39.335942Z","iopub.status.idle":"2024-08-31T04:35:50.767953Z","shell.execute_reply.started":"2024-08-31T03:31:39.335906Z","shell.execute_reply":"2024-08-31T04:35:50.767016Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.8 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240831_033312-aiijrigr</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/aditya0911das/huggingface/runs/aiijrigr' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/aditya0911das/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/aditya0911das/huggingface' target=\"_blank\">https://wandb.ai/aditya0911das/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/aditya0911das/huggingface/runs/aiijrigr' target=\"_blank\">https://wandb.ai/aditya0911das/huggingface/runs/aiijrigr</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='10950' max='10950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10950/10950 1:02:19, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>5.194200</td>\n      <td>5.069376</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>4.843800</td>\n      <td>4.813616</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=10950, training_loss=5.1704162207477165, metrics={'train_runtime': 3848.8393, 'train_samples_per_second': 45.52, 'train_steps_per_second': 2.845, 'total_flos': 1.7167621364554752e+16, 'train_loss': 5.1704162207477165, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline\nqa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer,device=0)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T04:36:43.067281Z","iopub.execute_input":"2024-08-31T04:36:43.068038Z","iopub.status.idle":"2024-08-31T04:36:43.074625Z","shell.execute_reply.started":"2024-08-31T04:36:43.067998Z","shell.execute_reply":"2024-08-31T04:36:43.073481Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"context=\"I am Aditya Das. I study at NMIMS\"\nquestion='Where does Aditya study ?'\n\nresult = qa_pipeline({\n    'context': context,\n    'question': question\n})\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T05:16:18.969444Z","iopub.execute_input":"2024-08-31T05:16:18.970330Z","iopub.status.idle":"2024-08-31T05:16:18.988101Z","shell.execute_reply.started":"2024-08-31T05:16:18.970287Z","shell.execute_reply":"2024-08-31T05:16:18.987041Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"print(\"Prediction:\", result)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T05:16:19.285863Z","iopub.execute_input":"2024-08-31T05:16:19.286595Z","iopub.status.idle":"2024-08-31T05:16:19.293581Z","shell.execute_reply.started":"2024-08-31T05:16:19.286553Z","shell.execute_reply":"2024-08-31T05:16:19.292563Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Prediction: {'score': 0.009663555771112442, 'start': 28, 'end': 33, 'answer': 'NMIMS'}\n","output_type":"stream"}]},{"cell_type":"code","source":"predicted_start = result['start']\npredicted_end = result['end']\n\n\ntrue_answer = \"NMIMS\"\ntrue_start = context.find(true_answer)\ntrue_end = true_start + len(true_answer)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T05:16:30.436292Z","iopub.execute_input":"2024-08-31T05:16:30.437137Z","iopub.status.idle":"2024-08-31T05:16:30.442334Z","shell.execute_reply.started":"2024-08-31T05:16:30.437100Z","shell.execute_reply":"2024-08-31T05:16:30.441325Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"def compute_iou(pred, ref):\n    pred_tokens = set(range(pred['start_positions'], pred['end_positions']))\n    ref_tokens = set(range(ref['start_positions'], ref['end_positions']))\n    intersection = len(pred_tokens & ref_tokens)\n    union = len(pred_tokens | ref_tokens)\n    return intersection / union if union != 0 else 0","metadata":{"execution":{"iopub.status.busy":"2024-08-31T05:16:31.222755Z","iopub.execute_input":"2024-08-31T05:16:31.223150Z","iopub.status.idle":"2024-08-31T05:16:31.230783Z","shell.execute_reply.started":"2024-08-31T05:16:31.223112Z","shell.execute_reply":"2024-08-31T05:16:31.229610Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"pred = {'start_positions': predicted_start, 'end_positions': predicted_end}\nref = {'start_positions': true_start, 'end_positions': true_end}\n\n# Compute token-level IoU\niou_score = compute_iou(pred, ref)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T05:16:31.786733Z","iopub.execute_input":"2024-08-31T05:16:31.787096Z","iopub.status.idle":"2024-08-31T05:16:31.793791Z","shell.execute_reply.started":"2024-08-31T05:16:31.787062Z","shell.execute_reply":"2024-08-31T05:16:31.792616Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"print(\"Prediction:\", result['answer'])\nprint(\"True Answer:\", true_answer)\nprint(\"Token-level IoU:\", iou_score)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T05:16:32.284138Z","iopub.execute_input":"2024-08-31T05:16:32.284906Z","iopub.status.idle":"2024-08-31T05:16:32.293453Z","shell.execute_reply.started":"2024-08-31T05:16:32.284863Z","shell.execute_reply":"2024-08-31T05:16:32.292336Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Prediction: NMIMS\nTrue Answer: NMIMS\nToken-level IoU: 1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}